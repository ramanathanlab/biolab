# biolab/reporting/parsers.py

import hashlib
import json
from pathlib import Path

import yaml
import numpy as np
import pandas as pd

def parse_config_yaml(config_path: Path) -> dict[str, str]:
    """
    Parse the configuration YAML file and extract model information along with a unique model identifier.

    Parameters
    ----------
    config_path : Path
        Path to the config.yaml file.

    Returns
    -------
    dict[str, str]
        Dictionary containing:
          - model_id: A unique identifier generated by hashing the configuration.
          - display_name: A human-readable name (here derived from the pretrained model field).
          - pretrained_model_name_or_path: The pretrained model name/path from the config.
    """
    with open(config_path, 'r') as f:
        config_data = yaml.safe_load(f)

    lm_cfg = config_data.get("lm_config", {})

    # Generate a unique model_id by hashing the sorted JSON representation of the lm_config dictionary.
    config_str = json.dumps(lm_cfg, sort_keys=True)
    model_id = hashlib.md5(config_str.encode('utf-8')).hexdigest()

    # Use the pretrained_model_name_or_path as the basis for display_name.
    model_name = lm_cfg.get("name", "UnknownModel")
    if hasattr(lm_cfg, "pretrained_model_name_or_path"):
        model_name = lm_cfg.get("pretrained_model_name_or_path", "UnknownModel")
    elif hasattr(lm_cfg, "weights_path"):
        weight_path = Path(lm_cfg.get("weights_path", "UnknownModel"))
        # assume we are interested in the last two segments of the path
        model_name = "_".join(weight_path.parts[-2:])

    # limit display name to first 30 characters for better readability
    display_name = (f'{model_name} {model_id}')[:20]

    return {
        "model_id": model_id,
        "display_name": display_name,
        "model_name": model_name,
        "output_dir": config_data.get("output_dir", "UnknownOutputDir"),
    }

def parse_metric_file(metric_file: Path, model_info: dict[str, str]) -> pd.DataFrame:
    """
    Parse a metric file and return a DataFrame with metric details.
    
    Parameters
    ----------
    metric_file : Path
        Path to a .metrics file.
    model_info : dict[str, str]
        Dictionary containing model metadata from the config file (including 'model_id', 'display_name', and 'output_dir').
    
    Returns
    -------
    pd.DataFrame
        DataFrame with one or more rows corresponding to metric entries.
    """
    filename = metric_file.name
    # Infer task name from the file name, e.g. "Ankh_CaLM-Meltome.metrics" -> "CaLM-Meltome"
    parts = filename.replace(".metrics", "").split("_", maxsplit=1)
    task_name = parts[1] if len(parts) == 2 else "UnknownTask"

    with open(metric_file, 'r') as f:
        metric_entries = json.load(f)

    rows = []
    for entry in metric_entries:
        class_name = entry["class_name"]
        train_scores = entry.get("train_scores") or []
        test_scores = entry.get("test_scores") or []
        train_mean = float(np.mean(train_scores)) if train_scores else None
        test_mean = float(np.mean(test_scores)) if test_scores else None

        rows.append({
            "model_id": model_info["model_id"],
            "display_name": model_info["display_name"],
            "output_dir": model_info.get("output_dir", "UnknownOutput"),
            "task_name": task_name,
            "metric_name": class_name,
            "is_higher_better": entry.get("is_higher_better", True),
            "train_scores": train_scores,
            "test_scores": test_scores,
            "train_mean": train_mean,
            "test_mean": test_mean,
        })
    return pd.DataFrame(rows)


def parse_run_directory(run_dir: Path) -> pd.DataFrame:
    """
    Parse a run directory to extract the configuration and all associated metric files.

    Parameters
    ----------
    run_dir : Path
        Path to the run directory (must contain config.yaml and *.metrics files).

    Returns
    -------
    pd.DataFrame
        A DataFrame containing parsed information from the run.
    """
    config_path = run_dir / "config.yaml"
    if not config_path.exists():
        raise FileNotFoundError(f"config.yaml not found in {run_dir}")

    model_info = parse_config_yaml(config_path)
    metric_files = list(run_dir.glob("*.metrics"))

    df_list = [parse_metric_file(mf, model_info) for mf in metric_files]

    if df_list:
        combined = pd.concat(df_list, ignore_index=True)
    else:
        columns = [
            "model_id", "display_name", "task_name", "metric_name",
            "is_higher_better", "train_scores", "train_mean", "test_scores", "test_mean"
        ]
        combined = pd.DataFrame(columns=columns)
    return combined
