"""Aggregation and summarization statistics of model evaluation results."""

from __future__ import annotations

from collections import defaultdict

import numpy as np
import pandas as pd


def concat_lists(series_of_lists: pd.Series) -> list:
    """Flatten a series of lists into a single list.

    Parameters
    ----------
    series_of_lists : pd.Series
        Each entry is itself a list of scores.

    Returns
    -------
    list
        A single flattened list of all scores.
    """
    return [x for sub in series_of_lists for x in sub]


def combine_scores_and_aggregate(df: pd.DataFrame) -> pd.DataFrame:
    """Aggregate repeated runs by combining score lists and computing mean ± std.

    Expects that the DataFrame contains the following fields generated by
    the parsers:
      - model_id
      - display_name
      - output_dir
      - task_name
      - metric_name
      - is_higher_better
      - train_scores
      - test_scores

    Returns
    -------
    pd.DataFrame
        A DataFrame with aggregated train/test means and standard deviations.
    """
    group_cols = [
        'model_id',
        'display_name',
        'output_dir',
        'task_name',
        'metric_name',
        'is_higher_better',
    ]

    aggregated = df.groupby(group_cols, dropna=False, as_index=False).agg(
        {
            'train_scores': concat_lists,
            'test_scores': concat_lists,
        }
    )

    def mean_std(scores: list) -> tuple[float | None, float | None]:
        if not scores:
            return None, None
        arr = np.array(scores, dtype=float)
        return arr.mean(), arr.std(ddof=1)

    train_means, train_stds, test_means, test_stds = [], [], [], []
    for _, row in aggregated.iterrows():
        tr_mean, tr_std = mean_std(row['train_scores'])
        te_mean, te_std = mean_std(row['test_scores'])
        train_means.append(tr_mean)
        train_stds.append(tr_std)
        test_means.append(te_mean)
        test_stds.append(te_std)

    aggregated['train_mean'] = train_means
    aggregated['train_std'] = train_stds
    aggregated['test_mean'] = test_means
    aggregated['test_std'] = test_stds

    return aggregated


def make_pivot_for_metric(df_agg: pd.DataFrame, metric_name: str) -> pd.DataFrame:
    """Create a pivot table for one metric with tasks as rows and models as columns.

    The cell entries are formatted as "mean ± std", and the columns are sorted
    so that the leftmost column corresponds to the best-performing model on average
    for that metric.

    Parameters
    ----------
    df_agg : pd.DataFrame
        Aggregated DataFrame with metric results.
    metric_name : str
        The metric name to filter on.

    Returns
    -------
    pd.DataFrame
        Pivot table with tasks as rows and each model as a column.
    """
    metric_df = df_agg[df_agg['metric_name'] == metric_name].copy()

    def fmt(mean, std):
        if pd.isna(mean):
            return '–'
        if pd.isna(std) or std == 0:
            return f'{mean:.3f}'
        return f'{mean:.3f} ± {std:.3f}'

    metric_df['test_str'] = metric_df.apply(
        lambda row: fmt(row['test_mean'], row['test_std']),
        axis=1,
    )

    # Use display_name if available, else fallback to model_id
    metric_df['model_label'] = metric_df.get('display_name', metric_df['model_id'])

    pivot = metric_df.pivot_table(
        index='task_name',
        columns='model_label',
        values='test_str',
        aggfunc='first',  # expecting one value per (task, model)
    )
    pivot.sort_index(axis='index', inplace=True)

    if not metric_df.empty:
        is_hb = metric_df['is_higher_better'].iloc[0]
        avg_scores = metric_df.groupby('model_label')['test_mean'].mean()
        # Sort descending if higher is better, else ascending
        if is_hb:
            sorted_models = avg_scores.sort_values(ascending=False).index.tolist()
        else:
            sorted_models = avg_scores.sort_values(ascending=True).index.tolist()
        pivot = pivot.reindex(columns=sorted_models)

    return pivot


def compute_win_rates(df_agg: pd.DataFrame) -> pd.DataFrame:
    """Compute per-model win rates across tasks and metrics (both union & intersection).

    For each (task, metric) group, the model(s) with the best test_mean is declared
    the winner. "Union" means all tasks & metrics each model is present in.
    "Intersection" means the subset of tasks & metrics in which *all* models appear.

    Returns a DataFrame with columns:
        model                : The model identifier (display_name or model_id)
        wins_intersection    : Wins counting only intersection tasks
        wins_union           : Wins counting all tasks the model appears in
        possible_intersection: Number of intersection tasks the model was in
        possible_union       : Number of tasks the model was in
        win_rate_intersection: = wins_intersection / possible_intersection
        win_rate_union       : = wins_union / possible_union
    """
    df = df_agg.copy()
    if 'display_name' in df.columns:
        df['model'] = df['display_name']
    else:
        df['model'] = df['model_id']

    # Group (task, metric) → list of (model, test_mean)
    group_map = defaultdict(list)
    ihb_map = {}

    for row in df.itertuples(index=False):
        key = (row.task_name, row.metric_name)
        group_map[key].append((row.model, row.test_mean))
        ihb_map[key] = row.is_higher_better

    all_models = sorted(df['model'].unique().tolist())
    # Keep track of which models are present in each group
    presence_map = {
        key: {m for (m, _) in model_list} for key, model_list in group_map.items()
    }
    # Intersection tasks: only those that have *all* models
    intersection_tasks = [
        key
        for key, present_ids in presence_map.items()
        if set(all_models).issubset(present_ids)
    ]

    winners_union = {m: 0 for m in all_models}
    winners_intersection = {m: 0 for m in all_models}
    possible_union = {m: 0 for m in all_models}
    possible_intersection = {m: 0 for m in all_models}

    # Determine winners
    for key, model_list in group_map.items():
        is_hb = ihb_map[key]
        valid_list = [(m, x) for (m, x) in model_list if pd.notna(x)]
        if not valid_list:
            continue

        best_val = (
            max(x for (_, x) in valid_list)
            if is_hb
            else min(x for (_, x) in valid_list)
        )
        winning_models = [m for (m, x) in valid_list if x == best_val]
        present_ids = {m for (m, _) in valid_list}

        # Union counters
        for m in present_ids:
            possible_union[m] += 1
        for m in winning_models:
            winners_union[m] += 1

        # Intersection counters
        if key in intersection_tasks:
            for m in all_models:
                possible_intersection[m] += 1
            for m in winning_models:
                winners_intersection[m] += 1

    results = []
    for m in all_models:
        pi = possible_intersection[m]
        pu = possible_union[m]
        wi = winners_intersection[m]
        wu = winners_union[m]

        results.append(
            {
                'model': m,
                'wins_intersection': wi,
                'wins_union': wu,
                'possible_intersection': pi,
                'possible_union': pu,
                'win_rate_intersection': wi / pi if pi > 0 else 0.0,
                'win_rate_union': wu / pu if pu > 0 else 0.0,
            }
        )

    return pd.DataFrame(results)


def compute_simplified_win_rates(df_agg: pd.DataFrame) -> pd.DataFrame:
    """Return a simpler DataFrame with the union-only win rates.

    This is used by the Dash reporter to replicate its simpler "wins / possible"
    approach.

    Parameters
    ----------
    df_agg : pd.DataFrame
        Aggregated data with metrics, tasks, display names, etc.

    Returns
    -------
    pd.DataFrame
        Columns: [model, wins, possible, win_rate].
    """
    full = compute_win_rates(df_agg)
    # Rename columns to match the simpler approach
    simple = full.rename(
        columns={
            'wins_union': 'wins',
            'possible_union': 'possible',
            'win_rate_union': 'win_rate',
        }
    )[['model', 'wins', 'possible', 'win_rate']].copy()
    # Fill NaNs if any model was never possible
    simple['wins'] = simple['wins'].fillna(0).astype(int)
    simple['possible'] = simple['possible'].fillna(0).astype(int)
    simple['win_rate'] = simple['win_rate'].fillna(0)
    return simple
